Parser
======

This is the first in a series  of experiments, with the end goal being
creating  an  interpreter for  a  programming  language entirely  from
scratch,  in C,  using  no  tools or  libraries  save  the C  standard
library,  GCC, Make,  and a  text  editor.  Hand-writing  a lexer  and
parser is the first step of many.

The  parser needs  to  be  at least  LL(k),  because anything  simpler
struggles   to  recognize   grammars  with   infix-operators.  It   is
(relatively) easy to make grammars  LL(k), so a backtracking parser is
overkill. (It's not like I'm writing a C++ parser :-)) It is plausible
that  a predicated  parser is necessary, 

The trouble with 'let'
----------------------
If we  want to  be certain of  exactly what we  are parsing  before we
start  munching   tokens,  we   need  arbitrary  lookahead   to  parse
let-blocks

    // let for symbol definitions.
    let a = ... ,
    	b = ... .

    // let for let ... in ... blocks.
    let x = f(a),
    	y = g(a),
	z = h(a)
    in t(x, y, z).

so we can figure out if there is an 'in'-lexeme before the terminating
dot. The problem can be solved easily by using another keyword for one
of the two -- problem gone!

    // def for symbol definitions.
    let a = ... ,
    	b = ... .

    // let for let ... in ... blocks.
    let x = f(a),
    	y = g(a),
	z = h(a)
    in t(x, y, z).

This is  not quite as elegant,  because the two _really_  mean similar
things.  They both  define symbols!  The difference is  only the scope
they  define the  symbols  in.  I specifically  don't  want a  million
keywords.

We may be able to _cheat_  and parse everything that starts with 'let'
blindly until we can make a  decision, since the tree structure of the
expression up to that point is identical. We can find the 'in' keyword
with LL(1) lookahead.

The trouble with chained comparisons
------------------------------------
I want to allow chained comparisons, i.e.  'x < y < z' should evaluate
as if it was 'x < y and y < z', _not_ as if it was '(x < y) < z'. This
is  quite problematic  to represant  in  a homogenous  ast, because  I
specifically  do _not_  want to  evaluate y  twice. We  can, in  other
words, _not_ encode chained comparisons as

x_1 'op' x_2 'op' ... 'op' x_n ~

            And
	  /     \
	 op      \
	/ \       \
    x_n-1  x_n    And
                /     \
               op     ...
              / \       \
	  x_n-2 x_n-1	And
	  	      /     \
	             op      op
                    / \     / \
                  x_2 x_3 x_1 x_2

because, as we  can see, almost every node appears  in the tree twice!
When evaluating  or generating  bytecode it would  be _super_  hard to
avoid evaluating everythin twice. Not only is this inefficient, but if
the expressions have side-effects, or are random, the results could be
catastrophically wrong!

The _correct_  solution to this  problem is  most likely to  move away
from a homogenous tree completely, but because of the nice benefits of
using one [1] i don't want to do so.

Rather,  i have  opted  for  the following  "hack":  I  am encoding  a
heterogenous node for the comparisons, by constructing nodes which act
as metadata, in a homogenous tree.

The ASTComp,  ASTCompOps, and ASTCompOperands ast_class-es  encode the
same representation of chained comparisons  that is used in the Python
AST in the following way:

x_1 'op' x_2 'op' ... 'op' x_n ~

          Comp
	/  |   \
       /   |    \  
      /    |     \
    x_1 CompOps CompOperands
           |      |
	  x_2    'op'
	   |      |
	  ...    ...
	   |      |
	  x_n    'op'

Which han  be evaluated  using the  following algorithm,  or something
similar:

    result <- true
    left   <- eval(Comp.left_op)
    loop i = 0, ...
      right  <- eval(Comp.operands[i])
      op     <- Comp.ops[i]
      result <- op(left, right)
      if not result: // short circuit
        break
      left <- right
    return result
    
Which also short-cicuits correctly.

To-do list
----------
- Update the to-do list more than once
- Refactor the lexer to return error codes instead of crash
  - Write tests for failing cases that we can now test for
- Modularize the unit-testing library

Sources
-------
[1] Purr, Terance: Language Implementation Patterns